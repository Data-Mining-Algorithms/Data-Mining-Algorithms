import numpy as np
import pandas as pd

names = ['user_id', 'item_id','rating', 'timestamp']

df = pd.read_csv('u.data', sep='\t', names=names)

df.head()

n_users = df.user_id.unique().shape[0]
n_items = df.item_id.unique().shape[0]

print( str(n_users) + ' users available')

print( str(n_items) + ' items available')

ratings = np.zeros((n_users, n_items))
for row in df.itertuples():
    ratings[row[1]-1, row[2]-1] = row[3]
print (ratings)

sparsity = float(len(ratings.nonzero()[0]))
sparsity /= (ratings.shape[0] * ratings.shape[1])
sparsity *= 100
print ('Sparcity: {:4.2f}% '.format(sparsity) )

#Split the dataset into training and test sets

def train_test_split(ratings):
    test = np.zeros(ratings.shape)
    train = ratings.copy()
    for user in range(ratings.shape[0]):
        test_ratings = np.random.choice(ratings[user, :].nonzero()[0],
                                        size=10,
                                        replace=False)
        train[user, test_ratings] = 0.
        test[user, test_ratings] = ratings[user, test_ratings]

    assert(np.all((train * test)==0))
    return train, test

train, test = train_test_split(ratings)

def f_similarity(ratings, kind='user', epsilon=1e-9):
    # epsilon -> small number for handling dived-by-zero errors
    if kind == 'user':
        sim = ratings.dot(ratings.T) + epsilon
    elif kind == 'item':
        sim = ratings.T.dot(ratings) + epsilon
    norms = np.array([np.sqrt(np.diagonal(sim))])
    return (sim / norms / norms.T)


user_similarity = f_similarity(train, kind='user')
item_similarity = f_similarity(train, kind='item')

#Now I print the similarity matrix

print ( item_similarity[:4, :4] )


def predict(ratings, similarity, kind='user'):
    if kind == 'user':
        return similarity.dot(ratings) / np.array([np.abs(similarity).sum(axis=1)]).T
    elif kind == 'item':
        return ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])


# I use the mean square error function as validation metric
from sklearn.metrics import mean_squared_error

def get_mse(pred, actual):
    # Ignore nonzero terms.
    pred = pred[actual.nonzero()].flatten()
    actual = actual[actual.nonzero()].flatten()
    return mean_squared_error(pred, actual)

item_prediction = predict(train, item_similarity, kind='item')
user_prediction = predict(train, user_similarity, kind='user')

#Now I show both user and item based colaborative filtering using Mean Square Error function
print ('User-based: ' + str(get_mse(user_prediction, test)) )
print ('Item-based: ' + str(get_mse(item_prediction, test)) )
